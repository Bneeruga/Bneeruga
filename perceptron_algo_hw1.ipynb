{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "perceptron_algo_hw1",
      "provenance": [],
      "authorship_tag": "ABX9TyPjlAWCR7Lup9/yGNJYKXwL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bneeruga/Bneeruga/blob/main/perceptron_algo_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LgWZR8gys3_",
        "outputId": "0b6e16db-f0a4-4c3d-9a03-b4cc5c98acbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error_training : 6.5 ; accuracy for step 0 : 93.5\n",
            "error_training : 1.5 ; accuracy for step 1 : 98.5\n",
            "error_training : 0.6 ; accuracy for step 2 : 99.4\n",
            "error_training : 0.4 ; accuracy for step 3 : 99.6\n",
            "error_training : 0.8 ; accuracy for step 4 : 99.2\n",
            "error_training : 0.4 ; accuracy for step 5 : 99.6\n",
            "error_training : 0.2 ; accuracy for step 6 : 99.8\n",
            "error_training : 0.5 ; accuracy for step 7 : 99.5\n",
            "error_training : 0.1 ; accuracy for step 8 : 99.9\n",
            "error_training : 0.0 ; accuracy for step 9 : 100.0\n",
            "errortest : 1.3 ; accuracy   : 98.7\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import axis\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_lables),(test_images,test_lables) = mnist.load_data()\n",
        "index_train = np.where( (train_lables == 4) | (train_lables == 5))\n",
        "index_test = np.where( (test_lables == 4) | (test_lables == 5))\n",
        "\n",
        "train_images_26 = train_images[index_train]\n",
        "#flatenning\n",
        "train_images_26 = train_images_26.reshape((len(train_images_26), train_images_26[1].size)) \n",
        "train_lables_26 = train_lables[index_train].astype( 'int')\n",
        "\n",
        "test_images_26 = test_images[index_test]\n",
        "test_images_26 = test_images_26.reshape((len(test_images_26), test_images_26[1].size)) \n",
        "test_lables_26 = test_lables[index_test].astype( 'int')\n",
        "\n",
        "train_lables_26[np.where(train_lables_26 == 4)] = -1\n",
        "train_lables_26[np.where(train_lables_26 == 5)] = 1\n",
        "\n",
        "test_lables_26[np.where(test_lables_26 == 4)] = -1\n",
        "test_lables_26[np.where(test_lables_26 == 5)] = 1\n",
        "\n",
        "\n",
        "train_images_26_w_dummy = np.insert(train_images_26,784,1,axis =1 )/255\n",
        "test_images_26_w_dummy = np.insert(test_images_26,784,1,axis =1 )/255\n",
        "\n",
        "train_images_26_w_dummy = train_images_26_w_dummy [range(1000)]\n",
        "train_lables_26_w_dummy = train_lables_26[range(1000)]\n",
        "\n",
        "test_images_26_w_dummy = test_images_26_w_dummy [range(1000)]\n",
        "test_lables_26_w_dummy = test_lables_26[range(1000)]\n",
        "\n",
        "setsize= 0.1\n",
        "iterations = 10\n",
        "weights = np.ones(train_images_26_w_dummy.shape[1])\n",
        "for it in range(iterations):\n",
        "  y_train_lable = []\n",
        "  error_training = 0\n",
        "  for i in range(train_images_26_w_dummy.shape[0]):\n",
        "      predict_train = np.dot(weights,train_images_26_w_dummy[i])\n",
        "      \n",
        "      if (predict_train) < 0:\n",
        "        y_train_lable.append(-1)\n",
        "      else:\n",
        "        y_train_lable.append(1)\n",
        "\n",
        "      if y_train_lable[i] != train_lables_26_w_dummy[i]:\n",
        "        error_training += 1\n",
        "\n",
        "      if (predict_train * train_lables_26_w_dummy[i]) <= 0:\n",
        "        weights += 0.1 * (train_lables_26_w_dummy[i])*train_images_26_w_dummy[i]\n",
        "        \n",
        "  print(f'error_training : {round((error_training/i), 3)*100} ; accuracy for step {it} : {(accuracy_score(train_lables_26_w_dummy,y_train_lable))*100}')\n",
        "\n",
        "\n",
        "y_test_lable = []\n",
        "error_test = 0\n",
        "for j in range(test_images_26_w_dummy.shape[0]):\n",
        " predicttest = np.dot(weights,test_images_26_w_dummy[j])\n",
        " if (predicttest) < 0:\n",
        "   y_test_lable.append(-1)\n",
        " else:\n",
        "   y_test_lable.append(1)\n",
        " if y_test_lable[j] != test_lables_26_w_dummy[j]:\n",
        "   error_test += 1\n",
        "\n",
        "print(f'errortest : {round((error_test/j), 3)*100} ; accuracy   : {(accuracy_score(test_lables_26_w_dummy,y_test_lable))*100}')\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "SSfRu2XPD8TL"
      }
    }
  ]
}